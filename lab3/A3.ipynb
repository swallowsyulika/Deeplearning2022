{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bfa317-5d5e-4c05-bc63-f13880f5d1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30b1f81-92cd-4fe0-ac15-b003ef14e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2 NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.get_device_name(device))\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "hidden_size = 512\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 0.4\n",
    "LR = 0.05\n",
    "\n",
    "reference = 'variable'\n",
    "output = 'varable'\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365b0749-e24d-4e8b-89b2-9bd5caecd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./train.json\"\n",
    "test_data_path = \"./test.json\"\n",
    "new_test_data_path = \"./new_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0dbf971-a400-4690-817a-476e49568619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(net, save_path, name: str):\n",
    "    torch.save(net.state_dict(), os.path.join(save_path, f\"checkpoint_{name}.weight\"))\n",
    "\n",
    "def load_weight(net, save_path, name: str):\n",
    "    net.load_state_dict(torch.load(os.path.join(save_path, f\"checkpoint_{name}.weight\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cab9b4-3dc7-4a25-bf99-898fce536ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path):\n",
    "        self.data_path = path\n",
    "        self.data = []\n",
    "        self.vocab_table_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.vocab_table_word2idx = {}\n",
    "\n",
    "        # read json\n",
    "        with open(self.data_path) as f:\n",
    "            data_json = json.load(f)\n",
    "        # combine inputs and labels\n",
    "        for ele in data_json:\n",
    "            inputs = ele[\"input\"]\n",
    "            label = ele[\"target\"]\n",
    "            for ins in inputs:\n",
    "                self.data.append([ins, label])\n",
    "\n",
    "        # make vocab table\n",
    "        for idx, ele in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            self.vocab_table_idx2word[idx+2] = ele\n",
    "        self.vocab_table_word2idx = {v: k for k, v in self.vocab_table_idx2word.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx = idx % len(self.data)\n",
    "\n",
    "        input = self.data[idx][0]\n",
    "        label = self.data[idx][1]\n",
    "\n",
    "        # char to idx\n",
    "        idx_input = np.array([0] + [self.vocab_table_word2idx[ele] for ele in input] + [1])\n",
    "        idx_label = np.array([0] + [self.vocab_table_word2idx[ele] for ele in label] + [1])\n",
    "        \n",
    "        return torch.from_numpy(idx_input.reshape(-1, 1)).to(device), torch.from_numpy(idx_label.reshape(-1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903013dd-27d5-4930-b220-4ddd1f83ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0],\n",
      "        [ 2],\n",
      "        [14],\n",
      "        [ 6],\n",
      "        [19],\n",
      "        [ 2],\n",
      "        [ 4],\n",
      "        [ 2],\n",
      "        [ 1]], device='cuda:2')\n",
      "torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "dl = Dataloader(train_data_path)\n",
    "x, y = dl[0]\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e142afa3-80fc-4051-b8d4-3f7ae7e80360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer=1, bi=False, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latyer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.latyer, bidirectional=self.bi, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)  # remove view() when input all tensor\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device))\n",
    "\n",
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, layer=1, bi=False, dropout=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.layer, bidirectional=self.bi, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * (2 if self.bi else 1), output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])    \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71fc385-d73e-45c5-baa9-22cfcf646afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=20):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "    # ####\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d3ed51-3e37-43dd-a05f-0c6dc244d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "    training_pairs = Dataloader(train_data_path)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "\n",
    "#trainIters(encoder1, decoder1, 200000, print_every=5000, learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cea62-0246-4b76-9db7-e32f6a48591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 49s (- 383m 15s) (12925 2%) 1.1622\n",
      "15m 42s (- 377m 10s) (25850 4%) 0.9058\n",
      "23m 30s (- 368m 24s) (38775 6%) 0.7933\n",
      "31m 22s (- 360m 46s) (51700 8%) 0.7071\n",
      "39m 10s (- 352m 36s) (64625 10%) 0.6386\n",
      "47m 0s (- 344m 41s) (77550 12%) 0.5792\n",
      "54m 51s (- 336m 59s) (90475 14%) 0.5410\n",
      "62m 37s (- 328m 45s) (103400 16%) 0.4939\n",
      "70m 28s (- 321m 4s) (116325 18%) 0.4699\n",
      "77m 57s (- 311m 48s) (129250 20%) 0.4427\n",
      "85m 50s (- 304m 21s) (142175 22%) 0.4151\n",
      "93m 40s (- 296m 38s) (155100 24%) 0.4033\n",
      "101m 36s (- 289m 10s) (168025 26%) 0.3908\n",
      "109m 41s (- 282m 2s) (180950 28%) 0.3823\n",
      "117m 42s (- 274m 38s) (193875 30%) 0.3601\n",
      "125m 31s (- 266m 44s) (206800 32%) 0.3501\n",
      "133m 29s (- 259m 7s) (219725 34%) 0.3324\n",
      "141m 23s (- 251m 22s) (232650 36%) 0.3395\n",
      "149m 22s (- 243m 43s) (245575 38%) 0.3310\n",
      "157m 10s (- 235m 45s) (258500 40%) 0.3350\n",
      "165m 6s (- 228m 0s) (271425 42%) 0.3100\n",
      "173m 7s (- 220m 20s) (284350 44%) 0.3079\n",
      "180m 27s (- 211m 50s) (297275 46%) 0.3161\n",
      "188m 23s (- 204m 5s) (310200 48%) 0.3054\n",
      "196m 26s (- 196m 26s) (323125 50%) 0.2929\n",
      "204m 20s (- 188m 37s) (336050 52%) 0.2995\n",
      "212m 26s (- 180m 57s) (348975 54%) 0.2985\n",
      "220m 26s (- 173m 12s) (361900 56%) 0.2885\n",
      "228m 9s (- 165m 12s) (374825 57%) 0.2776\n",
      "236m 14s (- 157m 29s) (387750 60%) 0.2906\n",
      "244m 12s (- 149m 40s) (400675 62%) 0.2823\n",
      "252m 13s (- 141m 52s) (413600 64%) 0.2729\n",
      "260m 11s (- 134m 2s) (426525 66%) 0.2816\n",
      "266m 23s (- 125m 21s) (439450 68%) 0.2688\n",
      "273m 56s (- 117m 24s) (452375 70%) 0.2773\n",
      "280m 45s (- 109m 10s) (465300 72%) 0.2794\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    encoder1 = EncoderRNN(vocab_size, hidden_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "    decoder1 = DecoderRNN(hidden_size, vocab_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "    trainIters(encoder1, decoder1, 646250, print_every=12925, learning_rate=LR)\n",
    "except KeyboardInterrupt:\n",
    "    save_weight(encoder1, \"./checkpoint\", \"encoderjpV2_interrupt\")\n",
    "    save_weight(decoder1, \"./checkpoint\", \"decoderjpV2_interrupt\")\n",
    "    print(\"save interrupt\")\n",
    "save_weight(encoder1, \"./checkpoint\", \"encoderjpV2\")\n",
    "save_weight(decoder1, \"./checkpoint\", \"decoderjpV2\")\n",
    "print(\"save final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709c92e2-762e-45cb-a596-19e71a820689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1622, 0.9058, 0.7933, 0.7071, 0.6386, 0.5792, 0.541, 0.4939, 0.4699, 0.4427, 0.4151, 0.4033, 0.3908, 0.3823, 0.3601, 0.3501, 0.3324, 0.3395, 0.331, 0.335, 0.31, 0.3079, 0.3161, 0.3054, 0.2929, 0.2995, 0.2985, 0.2885, 0.2776, 0.2906, 0.2823, 0.2729, 0.2816, 0.2688, 0.2773, 0.2794]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake = \"\"\"7m 49s (- 383m 15s) (12925 2%) 1.1622\n",
    "15m 42s (- 377m 10s) (25850 4%) 0.9058\n",
    "23m 30s (- 368m 24s) (38775 6%) 0.7933\n",
    "31m 22s (- 360m 46s) (51700 8%) 0.7071\n",
    "39m 10s (- 352m 36s) (64625 10%) 0.6386\n",
    "47m 0s (- 344m 41s) (77550 12%) 0.5792\n",
    "54m 51s (- 336m 59s) (90475 14%) 0.5410\n",
    "62m 37s (- 328m 45s) (103400 16%) 0.4939\n",
    "70m 28s (- 321m 4s) (116325 18%) 0.4699\n",
    "77m 57s (- 311m 48s) (129250 20%) 0.4427\n",
    "85m 50s (- 304m 21s) (142175 22%) 0.4151\n",
    "93m 40s (- 296m 38s) (155100 24%) 0.4033\n",
    "101m 36s (- 289m 10s) (168025 26%) 0.3908\n",
    "109m 41s (- 282m 2s) (180950 28%) 0.3823\n",
    "117m 42s (- 274m 38s) (193875 30%) 0.3601\n",
    "125m 31s (- 266m 44s) (206800 32%) 0.3501\n",
    "133m 29s (- 259m 7s) (219725 34%) 0.3324\n",
    "141m 23s (- 251m 22s) (232650 36%) 0.3395\n",
    "149m 22s (- 243m 43s) (245575 38%) 0.3310\n",
    "157m 10s (- 235m 45s) (258500 40%) 0.3350\n",
    "165m 6s (- 228m 0s) (271425 42%) 0.3100\n",
    "173m 7s (- 220m 20s) (284350 44%) 0.3079\n",
    "180m 27s (- 211m 50s) (297275 46%) 0.3161\n",
    "188m 23s (- 204m 5s) (310200 48%) 0.3054\n",
    "196m 26s (- 196m 26s) (323125 50%) 0.2929\n",
    "204m 20s (- 188m 37s) (336050 52%) 0.2995\n",
    "212m 26s (- 180m 57s) (348975 54%) 0.2985\n",
    "220m 26s (- 173m 12s) (361900 56%) 0.2885\n",
    "228m 9s (- 165m 12s) (374825 57%) 0.2776\n",
    "236m 14s (- 157m 29s) (387750 60%) 0.2906\n",
    "244m 12s (- 149m 40s) (400675 62%) 0.2823\n",
    "252m 13s (- 141m 52s) (413600 64%) 0.2729\n",
    "260m 11s (- 134m 2s) (426525 66%) 0.2816\n",
    "266m 23s (- 125m 21s) (439450 68%) 0.2688\n",
    "273m 56s (- 117m 24s) (452375 70%) 0.2773\n",
    "280m 45s (- 109m 10s) (465300 72%) 0.2794\"\"\"\n",
    "a = [float(x.split()[-1]) for x in [j for j in fake.split(\"\\n\")]]\n",
    "import matplotlib.pyplot as plt\n",
    "print(a)\n",
    "plt.plot(a)\n",
    "plt.title(\"train loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4b4485-df03-42ac-a750-451f0b990a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, hidden_size, layer=3, bi=True).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size, layer=3, bi=True).to(device)\n",
    "load_weight(encoder1, \"./checkpoint\", \"encoderjpV2\")\n",
    "load_weight(decoder1, \"./checkpoint\", \"decoderjpV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c146039-93c7-4cb3-b855-a43fc43c16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, path, max_length=20, show=True):\n",
    "    # your own dataloader\n",
    "    testing_pairs = Dataloader(path)\n",
    "    print(f\"testing num pair: {len(testing_pairs)}\")\n",
    "    bleu4 = 0\n",
    "    with torch.no_grad():\n",
    "        for iter in range(1, len(testing_pairs)+1):\n",
    "            testing_pair = testing_pairs[iter - 1]\n",
    "            input_tensor = testing_pair[0]\n",
    "            target_tensor = testing_pair[1]\n",
    "\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            output_list = []\n",
    "            \n",
    "\n",
    "            for di in range(max_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                if decoder_input.cpu().numpy().item() == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    output_list.append(decoder_input.cpu().numpy())\n",
    "\n",
    "            input_list = input_tensor.detach().cpu().numpy()\n",
    "            label_list = target_tensor.detach().cpu().numpy()\n",
    "\n",
    "            input_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in input_list[1:-1]])\n",
    "            label_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in label_list[1:-1]])\n",
    "            pred_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in output_list[1:]])\n",
    "\n",
    "            bleu4 += compute_bleu(pred_word, label_word)\n",
    "\n",
    "            if show:\n",
    "                print(\"=\"*20)\n",
    "                print(f\"input:\\t{input_word}\")\n",
    "                print(f\"target:\\t{label_word}\")\n",
    "                print(f\"pred:\\t{pred_word}\")\n",
    "\n",
    "        print(bleu4/len(testing_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a188bd62-5b54-43d5-9360-bca13eec9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 12925\n",
      "0.7856788355000721\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, train_data_path, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ac3a1d-355d-4744-8cb8-13c70113a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tcontenpted\n",
      "target:\tcontented\n",
      "pred:\tcontented\n",
      "====================\n",
      "input:\tbegining\n",
      "target:\tbeginning\n",
      "pred:\tbeginning\n",
      "====================\n",
      "input:\tproblam\n",
      "target:\tproblem\n",
      "pred:\tproblem\n",
      "====================\n",
      "input:\tdirven\n",
      "target:\tdriven\n",
      "pred:\tdrirven\n",
      "====================\n",
      "input:\tecstacy\n",
      "target:\tecstasy\n",
      "pred:\tecstasy\n",
      "====================\n",
      "input:\tjuce\n",
      "target:\tjuice\n",
      "pred:\tjuece\n",
      "====================\n",
      "input:\tlocaly\n",
      "target:\tlocally\n",
      "pred:\tlocally\n",
      "====================\n",
      "input:\tcompair\n",
      "target:\tcompare\n",
      "pred:\tcompare\n",
      "====================\n",
      "input:\tpronounciation\n",
      "target:\tpronunciation\n",
      "pred:\tpronunciation\n",
      "====================\n",
      "input:\ttransportibility\n",
      "target:\ttransportability\n",
      "pred:\ttransportability\n",
      "====================\n",
      "input:\tminiscule\n",
      "target:\tminuscule\n",
      "pred:\tminuscule\n",
      "====================\n",
      "input:\tindependant\n",
      "target:\tindependent\n",
      "pred:\tindependent\n",
      "====================\n",
      "input:\taranged\n",
      "target:\tarranged\n",
      "pred:\tarrenee\n",
      "====================\n",
      "input:\tpoartry\n",
      "target:\tpoetry\n",
      "pred:\tportey\n",
      "====================\n",
      "input:\tleval\n",
      "target:\tlevel\n",
      "pred:\tlevel\n",
      "====================\n",
      "input:\tbasicaly\n",
      "target:\tbasically\n",
      "pred:\tbasically\n",
      "====================\n",
      "input:\ttriangulaur\n",
      "target:\ttriangular\n",
      "pred:\ttrianguar\n",
      "====================\n",
      "input:\tunexpcted\n",
      "target:\tunexpected\n",
      "pred:\tunexpected\n",
      "====================\n",
      "input:\tstanerdizing\n",
      "target:\tstandardizing\n",
      "pred:\tstandardizing\n",
      "====================\n",
      "input:\tvarable\n",
      "target:\tvariable\n",
      "pred:\tvariable\n",
      "====================\n",
      "input:\tneigbours\n",
      "target:\tneighbours\n",
      "pred:\tneighbours\n",
      "====================\n",
      "input:\tenxt\n",
      "target:\tnext\n",
      "pred:\tnext\n",
      "====================\n",
      "input:\tpowerfull\n",
      "target:\tpowerful\n",
      "pred:\tpowerful\n",
      "====================\n",
      "input:\tpractial\n",
      "target:\tpractical\n",
      "pred:\tpractical\n",
      "====================\n",
      "input:\trepatition\n",
      "target:\trepartition\n",
      "pred:\trepetition\n",
      "====================\n",
      "input:\trepentence\n",
      "target:\trepentance\n",
      "pred:\trepentance\n",
      "====================\n",
      "input:\tsubstracts\n",
      "target:\tsubtracts\n",
      "pred:\tsubtracts\n",
      "====================\n",
      "input:\tbeed\n",
      "target:\tbead\n",
      "pred:\tbead\n",
      "====================\n",
      "input:\tbeame\n",
      "target:\tbeam\n",
      "pred:\tdeem\n",
      "====================\n",
      "input:\tdecieve\n",
      "target:\tdeceive\n",
      "pred:\tdeceive\n",
      "====================\n",
      "input:\tdecant\n",
      "target:\tdecent\n",
      "pred:\tdecent\n",
      "====================\n",
      "input:\tdag\n",
      "target:\tdog\n",
      "pred:\thog\n",
      "====================\n",
      "input:\tdaing\n",
      "target:\tdoing\n",
      "pred:\thoinn\n",
      "====================\n",
      "input:\texpence\n",
      "target:\texpense\n",
      "pred:\texpense\n",
      "====================\n",
      "input:\tfeirce\n",
      "target:\tfierce\n",
      "pred:\tphere\n",
      "====================\n",
      "input:\tfirery\n",
      "target:\tfiery\n",
      "pred:\tviry\n",
      "====================\n",
      "input:\tfought\n",
      "target:\tfort\n",
      "pred:\tforth\n",
      "====================\n",
      "input:\tfourth\n",
      "target:\tforth\n",
      "pred:\tfourth\n",
      "====================\n",
      "input:\tham\n",
      "target:\tharm\n",
      "pred:\thim\n",
      "====================\n",
      "input:\thavest\n",
      "target:\tharvest\n",
      "pred:\tharvest\n",
      "====================\n",
      "input:\timmdiately\n",
      "target:\timmediately\n",
      "pred:\timmediately\n",
      "====================\n",
      "input:\tinehaustible\n",
      "target:\tinexhaustible\n",
      "pred:\tinexhaustible\n",
      "====================\n",
      "input:\tjournel\n",
      "target:\tjournal\n",
      "pred:\tjournal\n",
      "====================\n",
      "input:\tleason\n",
      "target:\tlesson\n",
      "pred:\tlesson\n",
      "====================\n",
      "input:\tmantain\n",
      "target:\tmaintain\n",
      "pred:\tmaintain\n",
      "====================\n",
      "input:\tmiricle\n",
      "target:\tmiracle\n",
      "pred:\tpirricle\n",
      "====================\n",
      "input:\toportunity\n",
      "target:\topportunity\n",
      "pred:\topportunity\n",
      "====================\n",
      "input:\tparenthasis\n",
      "target:\tparenthesis\n",
      "pred:\tparenthesis\n",
      "====================\n",
      "input:\trecetion\n",
      "target:\trecession\n",
      "pred:\tresession\n",
      "====================\n",
      "input:\tscadual\n",
      "target:\tschedule\n",
      "pred:\tschedule\n",
      "0.7762818421312118\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161c8304-9cce-4bb2-a758-3090b8b9a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tapreciate\n",
      "target:\tappreciate\n",
      "pred:\tappreciate\n",
      "====================\n",
      "input:\tappeciate\n",
      "target:\tappreciate\n",
      "pred:\tappreciate\n",
      "====================\n",
      "input:\tapprciate\n",
      "target:\tappreciate\n",
      "pred:\tapproximate\n",
      "====================\n",
      "input:\tapprecate\n",
      "target:\tappreciate\n",
      "pred:\tappreciate\n",
      "====================\n",
      "input:\tapprecite\n",
      "target:\tappreciate\n",
      "pred:\tapprecite\n",
      "====================\n",
      "input:\tluve\n",
      "target:\tlove\n",
      "pred:\tlove\n",
      "====================\n",
      "input:\tculd\n",
      "target:\tcold\n",
      "pred:\tcluld\n",
      "====================\n",
      "input:\theart\n",
      "target:\theart\n",
      "pred:\tshert\n",
      "====================\n",
      "input:\tteleviseon\n",
      "target:\ttelevision\n",
      "pred:\ttelevision\n",
      "====================\n",
      "input:\tthone\n",
      "target:\tphone\n",
      "pred:\tthro\n",
      "====================\n",
      "input:\tphace\n",
      "target:\tphase\n",
      "pred:\tphase\n",
      "====================\n",
      "input:\tpoam\n",
      "target:\tpoem\n",
      "pred:\tpoem\n",
      "====================\n",
      "input:\ttomorraw\n",
      "target:\ttomorrow\n",
      "pred:\ttomorrow\n",
      "====================\n",
      "input:\tpresishan\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresishion\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresisian\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresistion\n",
      "target:\tprecision\n",
      "pred:\tpresistion\n",
      "====================\n",
      "input:\tperver\n",
      "target:\tprefer\n",
      "pred:\tprever\n",
      "====================\n",
      "input:\tpredgudice\n",
      "target:\tprejudice\n",
      "pred:\tpreduceee\n",
      "====================\n",
      "input:\tpredgudis\n",
      "target:\tprejudice\n",
      "pred:\tpreguids\n",
      "====================\n",
      "input:\trecievor\n",
      "target:\treceiver\n",
      "pred:\treceiver\n",
      "====================\n",
      "input:\treciover\n",
      "target:\treceiver\n",
      "pred:\tresolver\n",
      "====================\n",
      "input:\trelieve\n",
      "target:\trelief\n",
      "pred:\trelieve\n",
      "====================\n",
      "input:\ttogather\n",
      "target:\ttogether\n",
      "pred:\ttogateer\n",
      "====================\n",
      "input:\tremuttance\n",
      "target:\tremittance\n",
      "pred:\tremattance\n",
      "====================\n",
      "input:\tdeposite\n",
      "target:\tdeposit\n",
      "pred:\tdesposit\n",
      "====================\n",
      "input:\tdeposittt\n",
      "target:\tdeposit\n",
      "pred:\tdesposit\n",
      "====================\n",
      "input:\tpeper\n",
      "target:\tpepper\n",
      "pred:\tpepper\n",
      "====================\n",
      "input:\tpepperrr\n",
      "target:\tpepper\n",
      "pred:\tspepper\n",
      "====================\n",
      "input:\temploye\n",
      "target:\temployee\n",
      "pred:\timploye\n",
      "====================\n",
      "input:\temployezz\n",
      "target:\temployee\n",
      "pred:\timployees\n",
      "====================\n",
      "input:\tbeest\n",
      "target:\tbest\n",
      "pred:\theeest\n",
      "====================\n",
      "input:\tbestt\n",
      "target:\tbest\n",
      "pred:\theast\n",
      "====================\n",
      "input:\taset\n",
      "target:\tbest\n",
      "pred:\tassett\n",
      "====================\n",
      "input:\tfeeture\n",
      "target:\tfeature\n",
      "pred:\tfeature\n",
      "====================\n",
      "input:\tfaeture\n",
      "target:\tfeature\n",
      "pred:\tphatore\n",
      "====================\n",
      "input:\tfeatture\n",
      "target:\tfeature\n",
      "pred:\tfeatture\n",
      "====================\n",
      "input:\tgorges\n",
      "target:\tgorgeous\n",
      "pred:\tgorgees\n",
      "====================\n",
      "input:\tgorgeus\n",
      "target:\tgorgeous\n",
      "pred:\tgorgeous\n",
      "====================\n",
      "input:\tgourgace\n",
      "target:\tgorgeous\n",
      "pred:\tgorressee\n",
      "====================\n",
      "input:\tgripe\n",
      "target:\tgrip\n",
      "pred:\tsrip\n",
      "====================\n",
      "input:\thienous\n",
      "target:\theinous\n",
      "pred:\theinous\n",
      "====================\n",
      "input:\thurple\n",
      "target:\tpurple\n",
      "pred:\tsurple\n",
      "====================\n",
      "input:\toccassional\n",
      "target:\toccasional\n",
      "pred:\toccasional\n",
      "====================\n",
      "input:\ttirumph\n",
      "target:\ttriumph\n",
      "pred:\ttriumph\n",
      "====================\n",
      "input:\ttriam\n",
      "target:\ttriumph\n",
      "pred:\ttriumph\n",
      "====================\n",
      "input:\tunforgatealbe\n",
      "target:\tunforgettable\n",
      "pred:\tunforguatee\n",
      "====================\n",
      "input:\tunforgattable\n",
      "target:\tunforgettable\n",
      "pred:\tunfortunatel\n",
      "====================\n",
      "input:\tvesiable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "====================\n",
      "input:\tvisable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "0.6408612442379978\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, new_test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8051015-d5e2-4a1e-983f-1012fe37338d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
