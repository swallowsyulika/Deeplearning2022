{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1484c88f-2819-4788-b7b8-17cc68a73013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d159c37f-bd61-4323-a083-d53df1cd8588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2 NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.get_device_name(device))\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "hidden_size = 256\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 0.8\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66043dfe-34f9-453c-99c6-2329acb2f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path, useonehot=False):\n",
    "        self.data_path = path\n",
    "        self.useonehot = useonehot\n",
    "        self.data = []\n",
    "        self.vocab_table_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.vocab_table_word2idx = {}\n",
    "\n",
    "        # read json\n",
    "        with open(self.data_path) as f:\n",
    "            data_json = json.load(f)\n",
    "        # combine inputs and labels\n",
    "        for ele in data_json:\n",
    "            inputs = ele[\"input\"]\n",
    "            label = ele[\"target\"]\n",
    "            for ins in inputs:\n",
    "                self.data.append([ins, label])\n",
    "\n",
    "        # make vocab table\n",
    "        for idx, ele in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            self.vocab_table_idx2word[idx+2] = ele\n",
    "        self.vocab_table_word2idx = {v: k for k, v in self.vocab_table_idx2word.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx = idx % len(self.data)\n",
    "\n",
    "        input = self.data[idx][0]\n",
    "        label = self.data[idx][1]\n",
    "\n",
    "        # char to idx\n",
    "        idx_input = np.array([0] + [self.vocab_table_word2idx[ele] for ele in input] + [1])\n",
    "        idx_label = np.array([0] + [self.vocab_table_word2idx[ele] for ele in label] + [1])\n",
    "        # idx to one-hot\n",
    "        if self.useonehot:\n",
    "            onehot_input = np.zeros((idx_input.size, vocab_size), dtype=np.int32)\n",
    "            onehot_input[np.arange(idx_input.size), idx_input] = 1\n",
    "            onehot_label = np.zeros((idx_label.size, vocab_size), dtype=np.int32)\n",
    "            onehot_label[np.arange(idx_label.size), idx_label] = 1\n",
    "\n",
    "            return torch.from_numpy(onehot_input).unsqueeze(1).to(device), torch.from_numpy(onehot_label).unsqueeze(1).to(device)\n",
    "        else:\n",
    "            return torch.from_numpy(idx_input.reshape(-1, 1)).to(device), torch.from_numpy(idx_label.reshape(-1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d435a73e-939f-40d6-87fc-25dce6e38879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "dl = Dataloader(\"./train.json\")\n",
    "print(dl[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7edb68-5c31-4eb2-a0db-583941041ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1, 28])\n"
     ]
    }
   ],
   "source": [
    "dl = Dataloader(\"./train.json\", useonehot=True)\n",
    "print(dl[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10846d80-b55b-41b3-95f8-374c993f8212",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d2184025e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f7a6f-0c8b-4ec6-97e0-00e5ebc32512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
