{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bfa317-5d5e-4c05-bc63-f13880f5d1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30b1f81-92cd-4fe0-ac15-b003ef14e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2 NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.get_device_name(device))\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "hidden_size = 512\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 0.4\n",
    "LR = 0.05\n",
    "\n",
    "reference = 'variable'\n",
    "output = 'varable'\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365b0749-e24d-4e8b-89b2-9bd5caecd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./train.json\"\n",
    "test_data_path = \"./test.json\"\n",
    "new_test_data_path = \"./new_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dbf971-a400-4690-817a-476e49568619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(net, save_path, name: str):\n",
    "    torch.save(net.state_dict(), os.path.join(save_path, f\"checkpoint_{name}.weight\"))\n",
    "\n",
    "def load_weight(net, save_path, name: str):\n",
    "    net.load_state_dict(torch.load(os.path.join(save_path, f\"checkpoint_{name}.weight\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cab9b4-3dc7-4a25-bf99-898fce536ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path):\n",
    "        self.data_path = path\n",
    "        self.data = []\n",
    "        self.vocab_table_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.vocab_table_word2idx = {}\n",
    "\n",
    "        # read json\n",
    "        with open(self.data_path) as f:\n",
    "            data_json = json.load(f)\n",
    "        # combine inputs and labels\n",
    "        for ele in data_json:\n",
    "            inputs = ele[\"input\"]\n",
    "            label = ele[\"target\"]\n",
    "            for ins in inputs:\n",
    "                self.data.append([ins, label])\n",
    "\n",
    "        # make vocab table\n",
    "        for idx, ele in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            self.vocab_table_idx2word[idx+2] = ele\n",
    "        self.vocab_table_word2idx = {v: k for k, v in self.vocab_table_idx2word.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx = idx % len(self.data)\n",
    "\n",
    "        input = self.data[idx][0]\n",
    "        label = self.data[idx][1]\n",
    "\n",
    "        # char to idx\n",
    "        idx_input = np.array([0] + [self.vocab_table_word2idx[ele] for ele in input] + [1])\n",
    "        idx_label = np.array([0] + [self.vocab_table_word2idx[ele] for ele in label] + [1])\n",
    "        \n",
    "        return torch.from_numpy(idx_input.reshape(-1, 1)).to(device), torch.from_numpy(idx_label.reshape(-1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e142afa3-80fc-4051-b8d4-3f7ae7e80360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer=1, bi=False, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latyer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.latyer, bidirectional=self.bi, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)  # remove view() when input all tensor\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device))\n",
    "\n",
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, layer=1, bi=False, dropout=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.layer, bidirectional=self.bi, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * (2 if self.bi else 1), output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])    \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71fc385-d73e-45c5-baa9-22cfcf646afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=20):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "    # ####\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d3ed51-3e37-43dd-a05f-0c6dc244d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "    training_pairs = Dataloader(train_data_path)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "\n",
    "#trainIters(encoder1, decoder1, 200000, print_every=5000, learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cea62-0246-4b76-9db7-e32f6a48591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 49s (- 383m 15s) (12925 2%) 1.1622\n",
      "15m 42s (- 377m 10s) (25850 4%) 0.9058\n",
      "23m 30s (- 368m 24s) (38775 6%) 0.7933\n",
      "31m 22s (- 360m 46s) (51700 8%) 0.7071\n",
      "39m 10s (- 352m 36s) (64625 10%) 0.6386\n",
      "47m 0s (- 344m 41s) (77550 12%) 0.5792\n",
      "54m 51s (- 336m 59s) (90475 14%) 0.5410\n",
      "62m 37s (- 328m 45s) (103400 16%) 0.4939\n",
      "70m 28s (- 321m 4s) (116325 18%) 0.4699\n",
      "77m 57s (- 311m 48s) (129250 20%) 0.4427\n",
      "85m 50s (- 304m 21s) (142175 22%) 0.4151\n",
      "93m 40s (- 296m 38s) (155100 24%) 0.4033\n",
      "101m 36s (- 289m 10s) (168025 26%) 0.3908\n",
      "109m 41s (- 282m 2s) (180950 28%) 0.3823\n",
      "117m 42s (- 274m 38s) (193875 30%) 0.3601\n",
      "125m 31s (- 266m 44s) (206800 32%) 0.3501\n",
      "133m 29s (- 259m 7s) (219725 34%) 0.3324\n",
      "141m 23s (- 251m 22s) (232650 36%) 0.3395\n",
      "149m 22s (- 243m 43s) (245575 38%) 0.3310\n",
      "157m 10s (- 235m 45s) (258500 40%) 0.3350\n",
      "165m 6s (- 228m 0s) (271425 42%) 0.3100\n",
      "173m 7s (- 220m 20s) (284350 44%) 0.3079\n",
      "180m 27s (- 211m 50s) (297275 46%) 0.3161\n",
      "188m 23s (- 204m 5s) (310200 48%) 0.3054\n",
      "196m 26s (- 196m 26s) (323125 50%) 0.2929\n",
      "204m 20s (- 188m 37s) (336050 52%) 0.2995\n",
      "212m 26s (- 180m 57s) (348975 54%) 0.2985\n",
      "220m 26s (- 173m 12s) (361900 56%) 0.2885\n",
      "228m 9s (- 165m 12s) (374825 57%) 0.2776\n",
      "236m 14s (- 157m 29s) (387750 60%) 0.2906\n",
      "244m 12s (- 149m 40s) (400675 62%) 0.2823\n",
      "252m 13s (- 141m 52s) (413600 64%) 0.2729\n",
      "260m 11s (- 134m 2s) (426525 66%) 0.2816\n",
      "266m 23s (- 125m 21s) (439450 68%) 0.2688\n",
      "273m 56s (- 117m 24s) (452375 70%) 0.2773\n",
      "280m 45s (- 109m 10s) (465300 72%) 0.2794\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    encoder1 = EncoderRNN(vocab_size, hidden_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "    decoder1 = DecoderRNN(hidden_size, vocab_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "    trainIters(encoder1, decoder1, 646250, print_every=12925, learning_rate=LR)\n",
    "except KeyboardInterrupt:\n",
    "    save_weight(encoder1, \"./checkpoint\", \"encoderjpV2_interrupt\")\n",
    "    save_weight(decoder1, \"./checkpoint\", \"decoderjpV2_interrupt\")\n",
    "    print(\"save interrupt\")\n",
    "save_weight(encoder1, \"./checkpoint\", \"encoderjpV2\")\n",
    "save_weight(decoder1, \"./checkpoint\", \"decoderjpV2\")\n",
    "print(\"save final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c4b4485-df03-42ac-a750-451f0b990a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, hidden_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size, layer=3, bi=True, dropout=0.2).to(device)\n",
    "load_weight(encoder1, \"./checkpoint\", \"encoderjpV2\")\n",
    "load_weight(decoder1, \"./checkpoint\", \"decoderjpV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c146039-93c7-4cb3-b855-a43fc43c16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, path, max_length=20, show=True):\n",
    "    # your own dataloader\n",
    "    testing_pairs = Dataloader(path)\n",
    "    print(f\"testing num pair: {len(testing_pairs)}\")\n",
    "    bleu4 = 0\n",
    "    with torch.no_grad():\n",
    "        for iter in range(1, len(testing_pairs)+1):\n",
    "            testing_pair = testing_pairs[iter - 1]\n",
    "            input_tensor = testing_pair[0]\n",
    "            target_tensor = testing_pair[1]\n",
    "\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            output_list = []\n",
    "            \n",
    "\n",
    "            for di in range(max_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                if decoder_input.cpu().numpy().item() == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    output_list.append(decoder_input.cpu().numpy())\n",
    "\n",
    "            input_list = input_tensor.detach().cpu().numpy()\n",
    "            label_list = target_tensor.detach().cpu().numpy()\n",
    "\n",
    "            input_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in input_list[1:-1]])\n",
    "            label_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in label_list[1:-1]])\n",
    "            pred_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in output_list[1:]])\n",
    "\n",
    "            bleu4 += compute_bleu(pred_word, label_word)\n",
    "\n",
    "            if show:\n",
    "                print(\"=\"*20)\n",
    "                print(f\"input:\\t{input_word}\")\n",
    "                print(f\"target:\\t{label_word}\")\n",
    "                print(f\"pred:\\t{pred_word}\")\n",
    "\n",
    "        print(bleu4/len(testing_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188bd62-5b54-43d5-9360-bca13eec9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 12925\n",
      "0.7277808812847557\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, train_data_path, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ac3a1d-355d-4744-8cb8-13c70113a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tcontenpted\n",
      "target:\tcontented\n",
      "pred:\tcontented\n",
      "====================\n",
      "input:\tbegining\n",
      "target:\tbeginning\n",
      "pred:\tbeginning\n",
      "====================\n",
      "input:\tproblam\n",
      "target:\tproblem\n",
      "pred:\tproblem\n",
      "====================\n",
      "input:\tdirven\n",
      "target:\tdriven\n",
      "pred:\tdrishen\n",
      "====================\n",
      "input:\tecstacy\n",
      "target:\tecstasy\n",
      "pred:\tecstasy\n",
      "====================\n",
      "input:\tjuce\n",
      "target:\tjuice\n",
      "pred:\tjuece\n",
      "====================\n",
      "input:\tlocaly\n",
      "target:\tlocally\n",
      "pred:\tlocally\n",
      "====================\n",
      "input:\tcompair\n",
      "target:\tcompare\n",
      "pred:\tcompare\n",
      "====================\n",
      "input:\tpronounciation\n",
      "target:\tpronunciation\n",
      "pred:\tpronunciation\n",
      "====================\n",
      "input:\ttransportibility\n",
      "target:\ttransportability\n",
      "pred:\ttransportability\n",
      "====================\n",
      "input:\tminiscule\n",
      "target:\tminuscule\n",
      "pred:\tminuscule\n",
      "====================\n",
      "input:\tindependant\n",
      "target:\tindependent\n",
      "pred:\tindependent\n",
      "====================\n",
      "input:\taranged\n",
      "target:\tarranged\n",
      "pred:\tarraged\n",
      "====================\n",
      "input:\tpoartry\n",
      "target:\tpoetry\n",
      "pred:\tportey\n",
      "====================\n",
      "input:\tleval\n",
      "target:\tlevel\n",
      "pred:\tlevel\n",
      "====================\n",
      "input:\tbasicaly\n",
      "target:\tbasically\n",
      "pred:\tbasically\n",
      "====================\n",
      "input:\ttriangulaur\n",
      "target:\ttriangular\n",
      "pred:\ttriangular\n",
      "====================\n",
      "input:\tunexpcted\n",
      "target:\tunexpected\n",
      "pred:\tunexected\n",
      "====================\n",
      "input:\tstanerdizing\n",
      "target:\tstandardizing\n",
      "pred:\tstandardizing\n",
      "====================\n",
      "input:\tvarable\n",
      "target:\tvariable\n",
      "pred:\tvariable\n",
      "====================\n",
      "input:\tneigbours\n",
      "target:\tneighbours\n",
      "pred:\tneighbours\n",
      "====================\n",
      "input:\tenxt\n",
      "target:\tnext\n",
      "pred:\tnext\n",
      "====================\n",
      "input:\tpowerfull\n",
      "target:\tpowerful\n",
      "pred:\tpowerful\n",
      "====================\n",
      "input:\tpractial\n",
      "target:\tpractical\n",
      "pred:\tpractical\n",
      "====================\n",
      "input:\trepatition\n",
      "target:\trepartition\n",
      "pred:\trepetition\n",
      "====================\n",
      "input:\trepentence\n",
      "target:\trepentance\n",
      "pred:\trepentance\n",
      "====================\n",
      "input:\tsubstracts\n",
      "target:\tsubtracts\n",
      "pred:\tsubtracts\n",
      "====================\n",
      "input:\tbeed\n",
      "target:\tbead\n",
      "pred:\tbead\n",
      "====================\n",
      "input:\tbeame\n",
      "target:\tbeam\n",
      "pred:\tdeem\n",
      "====================\n",
      "input:\tdecieve\n",
      "target:\tdeceive\n",
      "pred:\tdeceive\n",
      "====================\n",
      "input:\tdecant\n",
      "target:\tdecent\n",
      "pred:\tdescnnt\n",
      "====================\n",
      "input:\tdag\n",
      "target:\tdog\n",
      "pred:\thog\n",
      "====================\n",
      "input:\tdaing\n",
      "target:\tdoing\n",
      "pred:\tdoee\n",
      "====================\n",
      "input:\texpence\n",
      "target:\texpense\n",
      "pred:\texpense\n",
      "====================\n",
      "input:\tfeirce\n",
      "target:\tfierce\n",
      "pred:\tfierce\n",
      "====================\n",
      "input:\tfirery\n",
      "target:\tfiery\n",
      "pred:\tviry\n",
      "====================\n",
      "input:\tfought\n",
      "target:\tfort\n",
      "pred:\ttought\n",
      "====================\n",
      "input:\tfourth\n",
      "target:\tforth\n",
      "pred:\tfourth\n",
      "====================\n",
      "input:\tham\n",
      "target:\tharm\n",
      "pred:\thin\n",
      "====================\n",
      "input:\thavest\n",
      "target:\tharvest\n",
      "pred:\tharvest\n",
      "====================\n",
      "input:\timmdiately\n",
      "target:\timmediately\n",
      "pred:\timmediately\n",
      "====================\n",
      "input:\tinehaustible\n",
      "target:\tinexhaustible\n",
      "pred:\tinexhaustible\n",
      "====================\n",
      "input:\tjournel\n",
      "target:\tjournal\n",
      "pred:\tjournal\n",
      "====================\n",
      "input:\tleason\n",
      "target:\tlesson\n",
      "pred:\tlesson\n",
      "====================\n",
      "input:\tmantain\n",
      "target:\tmaintain\n",
      "pred:\tmaintain\n",
      "====================\n",
      "input:\tmiricle\n",
      "target:\tmiracle\n",
      "pred:\tmiracle\n",
      "====================\n",
      "input:\toportunity\n",
      "target:\topportunity\n",
      "pred:\topportunity\n",
      "====================\n",
      "input:\tparenthasis\n",
      "target:\tparenthesis\n",
      "pred:\tparenthesis\n",
      "====================\n",
      "input:\trecetion\n",
      "target:\trecession\n",
      "pred:\trestition\n",
      "====================\n",
      "input:\tscadual\n",
      "target:\tschedule\n",
      "pred:\tschedule\n",
      "0.772318407276377\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161c8304-9cce-4bb2-a758-3090b8b9a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tapreciate\n",
      "target:\tappreciate\n",
      "pred:\tappreciate\n",
      "====================\n",
      "input:\tappeciate\n",
      "target:\tappreciate\n",
      "pred:\tappreciate\n",
      "====================\n",
      "input:\tapprciate\n",
      "target:\tappreciate\n",
      "pred:\tippreciate\n",
      "====================\n",
      "input:\tapprecate\n",
      "target:\tappreciate\n",
      "pred:\tpprercite\n",
      "====================\n",
      "input:\tapprecite\n",
      "target:\tappreciate\n",
      "pred:\tapprecitt\n",
      "====================\n",
      "input:\tluve\n",
      "target:\tlove\n",
      "pred:\tlove\n",
      "====================\n",
      "input:\tculd\n",
      "target:\tcold\n",
      "pred:\tkolu\n",
      "====================\n",
      "input:\theart\n",
      "target:\theart\n",
      "pred:\thert\n",
      "====================\n",
      "input:\tteleviseon\n",
      "target:\ttelevision\n",
      "pred:\ttelevison\n",
      "====================\n",
      "input:\tthone\n",
      "target:\tphone\n",
      "pred:\tthron\n",
      "====================\n",
      "input:\tphace\n",
      "target:\tphase\n",
      "pred:\tphase\n",
      "====================\n",
      "input:\tpoam\n",
      "target:\tpoem\n",
      "pred:\tpoem\n",
      "====================\n",
      "input:\ttomorraw\n",
      "target:\ttomorrow\n",
      "pred:\ttomaworr\n",
      "====================\n",
      "input:\tpresishan\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresishion\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresisian\n",
      "target:\tprecision\n",
      "pred:\tprecision\n",
      "====================\n",
      "input:\tpresistion\n",
      "target:\tprecision\n",
      "pred:\tpresistion\n",
      "====================\n",
      "input:\tperver\n",
      "target:\tprefer\n",
      "pred:\tprever\n",
      "====================\n",
      "input:\tpredgudice\n",
      "target:\tprejudice\n",
      "pred:\tpreduccie\n",
      "====================\n",
      "input:\tpredgudis\n",
      "target:\tprejudice\n",
      "pred:\tpregueds\n",
      "====================\n",
      "input:\trecievor\n",
      "target:\treceiver\n",
      "pred:\treceiver\n",
      "====================\n",
      "input:\treciover\n",
      "target:\treceiver\n",
      "pred:\treceiver\n",
      "====================\n",
      "input:\trelieve\n",
      "target:\trelief\n",
      "pred:\trelieve\n",
      "====================\n",
      "input:\ttogather\n",
      "target:\ttogether\n",
      "pred:\ttogater\n",
      "====================\n",
      "input:\tremuttance\n",
      "target:\tremittance\n",
      "pred:\tremateance\n",
      "====================\n",
      "input:\tdeposite\n",
      "target:\tdeposit\n",
      "pred:\tdeposit\n",
      "====================\n",
      "input:\tdeposittt\n",
      "target:\tdeposit\n",
      "pred:\tdespotet\n",
      "====================\n",
      "input:\tpeper\n",
      "target:\tpepper\n",
      "pred:\tpepper\n",
      "====================\n",
      "input:\tpepperrr\n",
      "target:\tpepper\n",
      "pred:\trepper\n",
      "====================\n",
      "input:\temploye\n",
      "target:\temployee\n",
      "pred:\temploye\n",
      "====================\n",
      "input:\temployezz\n",
      "target:\temployee\n",
      "pred:\timployees\n",
      "====================\n",
      "input:\tbeest\n",
      "target:\tbest\n",
      "pred:\thepsts\n",
      "====================\n",
      "input:\tbestt\n",
      "target:\tbest\n",
      "pred:\theast\n",
      "====================\n",
      "input:\taset\n",
      "target:\tbest\n",
      "pred:\tessat\n",
      "====================\n",
      "input:\tfeeture\n",
      "target:\tfeature\n",
      "pred:\tfeature\n",
      "====================\n",
      "input:\tfaeture\n",
      "target:\tfeature\n",
      "pred:\tparttee\n",
      "====================\n",
      "input:\tfeatture\n",
      "target:\tfeature\n",
      "pred:\tfetiture\n",
      "====================\n",
      "input:\tgorges\n",
      "target:\tgorgeous\n",
      "pred:\tgorgees\n",
      "====================\n",
      "input:\tgorgeus\n",
      "target:\tgorgeous\n",
      "pred:\tgorgeous\n",
      "====================\n",
      "input:\tgourgace\n",
      "target:\tgorgeous\n",
      "pred:\tgorreaeee\n",
      "====================\n",
      "input:\tgripe\n",
      "target:\tgrip\n",
      "pred:\tsrip\n",
      "====================\n",
      "input:\thienous\n",
      "target:\theinous\n",
      "pred:\tinterious\n",
      "====================\n",
      "input:\thurple\n",
      "target:\tpurple\n",
      "pred:\tsurple\n",
      "====================\n",
      "input:\toccassional\n",
      "target:\toccasional\n",
      "pred:\toccasional\n",
      "====================\n",
      "input:\ttirumph\n",
      "target:\ttriumph\n",
      "pred:\ttriumph\n",
      "====================\n",
      "input:\ttriam\n",
      "target:\ttriumph\n",
      "pred:\ttriump\n",
      "====================\n",
      "input:\tunforgatealbe\n",
      "target:\tunforgettable\n",
      "pred:\tunforguatety\n",
      "====================\n",
      "input:\tunforgattable\n",
      "target:\tunforgettable\n",
      "pred:\tunforguateble\n",
      "====================\n",
      "input:\tvesiable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "====================\n",
      "input:\tvisable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "0.6076486096643279\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, new_test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8051015-d5e2-4a1e-983f-1012fe37338d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
