{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bfa317-5d5e-4c05-bc63-f13880f5d1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/pytorch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30b1f81-92cd-4fe0-ac15-b003ef14e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2 NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.get_device_name(device))\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "hidden_size = 512\n",
    "vocab_size = 29\n",
    "teacher_forcing_ratio = 0.8\n",
    "LR = 0.05\n",
    "\n",
    "reference = 'variable'\n",
    "output = 'varable'\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365b0749-e24d-4e8b-89b2-9bd5caecd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./train.json\"\n",
    "test_data_path = \"./test.json\"\n",
    "new_test_data_path = \"./new_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dbf971-a400-4690-817a-476e49568619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(net, save_path, name: str):\n",
    "    torch.save(net.state_dict(), os.path.join(save_path, f\"checkpoint_{name}.weight\"))\n",
    "\n",
    "def load_weight(net, save_path, name: str):\n",
    "    net.load_state_dict(torch.load(os.path.join(save_path, f\"checkpoint_{name}.weight\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cab9b4-3dc7-4a25-bf99-898fce536ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, path, batch=1):\n",
    "        self.data_path = path\n",
    "        self.data = []\n",
    "        self.vocab_table_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.vocab_table_word2idx = {}\n",
    "        self.maxlen = 0\n",
    "        self.batch = batch\n",
    "        self.idx = 0\n",
    "\n",
    "        # read json\n",
    "        with open(self.data_path) as f:\n",
    "            data_json = json.load(f)\n",
    "        # combine inputs and labels\n",
    "        for ele in data_json:\n",
    "            inputs = ele[\"input\"]\n",
    "            label = ele[\"target\"]\n",
    "            \n",
    "            if len(inputs) > self.maxlen:\n",
    "                self.maxlen = len(inputs)\n",
    "            if len(label) > self.maxlen:\n",
    "                self.maxlen = len(label)\n",
    "                \n",
    "            for ins in inputs:\n",
    "                self.data.append([ins, label])\n",
    "\n",
    "        # make vocab table\n",
    "        for idx, ele in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "            self.vocab_table_idx2word[idx+2] = ele\n",
    "        self.vocab_table_word2idx = {v: k for k, v in self.vocab_table_idx2word.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx = idx  % len(self.data) #\n",
    "    \n",
    "        inputs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(idx, self.batch):\n",
    "            input = self.data[i][0]\n",
    "            label = self.data[i][1]\n",
    "\n",
    "            # char to idx\n",
    "            idx_input = np.array([0] + [self.vocab_table_word2idx[ele] for ele in input] + [1] + [1] * (self.maxlen - len(input)))\n",
    "            idx_label = np.array([0] + [self.vocab_table_word2idx[ele] for ele in label] + [1] + [1] * (self.maxlen - len(label)))\n",
    "            \n",
    "            inputs.append(idx_input)\n",
    "            labels.append(idx_label)\n",
    "        \n",
    "        inputs = np.array(inputs).reshape(self.batch, -1, 1)\n",
    "        labels = np.array(labels).reshape(self.batch, -1, 1)\n",
    "        \n",
    "        self.idx += self.batch\n",
    "   \n",
    "        return inputs, labels\n",
    "        #return torch.from_numpy(idx_input.reshape(-1, 1)).to(device), torch.from_numpy(idx_label.reshape(-1, 1)).to(device)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e142afa3-80fc-4051-b8d4-3f7ae7e80360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer=1, bi=False):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latyer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.latyer, bidirectional=self.bi, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)  # remove view() when input all tensor\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.latyer * (2 if self.bi else 1), 1, self.hidden_size, device=device))\n",
    "\n",
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, layer=1, bi=False, dropout=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "        self.bi = bi\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=self.layer, bidirectional=self.bi, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * (2 if self.bi else 1), output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])    \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device), torch.zeros(self.layer * (2 if self.bi else 1), 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71fc385-d73e-45c5-baa9-22cfcf646afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=20):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "    # ####\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d3ed51-3e37-43dd-a05f-0c6dc244d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, eps, print_every=1000, plot_every=100, learning_rate=0.01, batch=16):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "    training_pairs = Dataloader(train_data_path, batch)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for ep in range(1, eps+1):\n",
    "        for i in range(0, len(training_pairs), batch):\n",
    "            training_pair = training_pairs[1 - 1]\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if ep % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, ep / n_iters),\n",
    "                                        ep, ep / n_iters * 100, print_loss_avg))\n",
    "\t\n",
    "\n",
    "encoder1 = EncoderRNN(vocab_size, hidden_size, layer=5, bi=True).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size, layer=5, bi=True).to(device)\n",
    "\n",
    "#trainIters(encoder1, decoder1, 200000, print_every=5000, learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756cea62-0246-4b76-9db7-e32f6a48591b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 20\u001b[0m, in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, eps, print_every, plot_every, learning_rate, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     23\u001b[0m plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn [7], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m      4\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m input_length \u001b[38;5;241m=\u001b[39m \u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m target_length \u001b[38;5;241m=\u001b[39m target_tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(max_length, encoder\u001b[38;5;241m.\u001b[39mhidden_size, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 400000, print_every=5000, learning_rate=LR, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a3ff6f-e858-42c8-a1fa-bf175bd3a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weight(encoder1, \"./checkpoint\", \"encoderhi512ly5bid03\")\n",
    "save_weight(decoder1, \"./checkpoint\", \"decoderhi512ly5bid03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b4485-df03-42ac-a750-451f0b990a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, hidden_size, layer=3, bi=False).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size, layer=3, bi=False).to(device)\n",
    "load_weight(encoder1, \"./checkpoint\", \"encoderjpV1\")\n",
    "load_weight(decoder1, \"./checkpoint\", \"decoderjpV1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c146039-93c7-4cb3-b855-a43fc43c16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, path, max_length=20, show=True):\n",
    "    # your own dataloader\n",
    "    testing_pairs = Dataloader(path)\n",
    "    print(f\"testing num pair: {len(testing_pairs)}\")\n",
    "    bleu4 = 0\n",
    "    with torch.no_grad():\n",
    "        for iter in range(1, len(testing_pairs)+1):\n",
    "            testing_pair = testing_pairs[iter - 1]\n",
    "            input_tensor = testing_pair[0]\n",
    "            target_tensor = testing_pair[1]\n",
    "\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            output_list = []\n",
    "            \n",
    "\n",
    "            for di in range(max_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                if decoder_input.cpu().numpy().item() == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    output_list.append(decoder_input.cpu().numpy())\n",
    "\n",
    "            input_list = input_tensor.detach().cpu().numpy()\n",
    "            label_list = target_tensor.detach().cpu().numpy()\n",
    "\n",
    "            input_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in input_list[1:-1]])\n",
    "            label_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in label_list[1:-1]])\n",
    "            pred_word = ''.join([testing_pairs.vocab_table_idx2word[x.item(0)] for x in output_list[1:]])\n",
    "\n",
    "            bleu4 += compute_bleu(pred_word, label_word)\n",
    "\n",
    "            if show:\n",
    "                print(\"=\"*20)\n",
    "                print(f\"input:\\t{input_word}\")\n",
    "                print(f\"target:\\t{label_word}\")\n",
    "                print(f\"pred:\\t{pred_word}\")\n",
    "\n",
    "        print(bleu4/len(testing_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a188bd62-5b54-43d5-9360-bca13eec9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 12925\n",
      "0.018224637193439048\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, train_data_path, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ac3a1d-355d-4744-8cb8-13c70113a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tcontenpted\n",
      "target:\tcontented\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\tbegining\n",
      "target:\tbeginning\n",
      "pred:\tmnnnnnnn\n",
      "====================\n",
      "input:\tproblam\n",
      "target:\tproblem\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tdirven\n",
      "target:\tdriven\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tecstacy\n",
      "target:\tecstasy\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tjuce\n",
      "target:\tjuice\n",
      "pred:\tmnnn\n",
      "====================\n",
      "input:\tlocaly\n",
      "target:\tlocally\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tcompair\n",
      "target:\tcompare\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tpronounciation\n",
      "target:\tpronunciation\n",
      "pred:\tmnnnnnnnnnnnnn\n",
      "====================\n",
      "input:\ttransportibility\n",
      "target:\ttransportability\n",
      "pred:\tmnnnnnnnnnnnnnnn\n",
      "====================\n",
      "input:\tminiscule\n",
      "target:\tminuscule\n",
      "pred:\tmnnnnnnnn\n",
      "====================\n",
      "input:\tindependant\n",
      "target:\tindependent\n",
      "pred:\tmnnnnnnnnnn\n",
      "====================\n",
      "input:\taranged\n",
      "target:\tarranged\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tpoartry\n",
      "target:\tpoetry\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tleval\n",
      "target:\tlevel\n",
      "pred:\tmnnnn\n",
      "====================\n",
      "input:\tbasicaly\n",
      "target:\tbasically\n",
      "pred:\tmnnnnnnn\n",
      "====================\n",
      "input:\ttriangulaur\n",
      "target:\ttriangular\n",
      "pred:\tmnnnnnnnnnn\n",
      "====================\n",
      "input:\tunexpcted\n",
      "target:\tunexpected\n",
      "pred:\tmnnnnnnnn\n",
      "====================\n",
      "input:\tstanerdizing\n",
      "target:\tstandardizing\n",
      "pred:\tmnnnnnnnnnnn\n",
      "====================\n",
      "input:\tvarable\n",
      "target:\tvariable\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tneigbours\n",
      "target:\tneighbours\n",
      "pred:\tmnnnnnnnn\n",
      "====================\n",
      "input:\tenxt\n",
      "target:\tnext\n",
      "pred:\tmnnn\n",
      "====================\n",
      "input:\tpowerfull\n",
      "target:\tpowerful\n",
      "pred:\tmnnnnnnnn\n",
      "====================\n",
      "input:\tpractial\n",
      "target:\tpractical\n",
      "pred:\tmnnnnnnn\n",
      "====================\n",
      "input:\trepatition\n",
      "target:\trepartition\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\trepentence\n",
      "target:\trepentance\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\tsubstracts\n",
      "target:\tsubtracts\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\tbeed\n",
      "target:\tbead\n",
      "pred:\tmnnn\n",
      "====================\n",
      "input:\tbeame\n",
      "target:\tbeam\n",
      "pred:\tmnnnn\n",
      "====================\n",
      "input:\tdecieve\n",
      "target:\tdeceive\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tdecant\n",
      "target:\tdecent\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tdag\n",
      "target:\tdog\n",
      "pred:\tnnn\n",
      "====================\n",
      "input:\tdaing\n",
      "target:\tdoing\n",
      "pred:\tmnnnn\n",
      "====================\n",
      "input:\texpence\n",
      "target:\texpense\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tfeirce\n",
      "target:\tfierce\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tfirery\n",
      "target:\tfiery\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tfought\n",
      "target:\tfort\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tfourth\n",
      "target:\tforth\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tham\n",
      "target:\tharm\n",
      "pred:\tnnn\n",
      "====================\n",
      "input:\thavest\n",
      "target:\tharvest\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\timmdiately\n",
      "target:\timmediately\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\tinehaustible\n",
      "target:\tinexhaustible\n",
      "pred:\tmnnnnnnnnnnn\n",
      "====================\n",
      "input:\tjournel\n",
      "target:\tjournal\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tleason\n",
      "target:\tlesson\n",
      "pred:\tmnnnnn\n",
      "====================\n",
      "input:\tmantain\n",
      "target:\tmaintain\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\tmiricle\n",
      "target:\tmiracle\n",
      "pred:\tmnnnnnn\n",
      "====================\n",
      "input:\toportunity\n",
      "target:\topportunity\n",
      "pred:\tmnnnnnnnnn\n",
      "====================\n",
      "input:\tparenthasis\n",
      "target:\tparenthesis\n",
      "pred:\tmnnnnnnnnnn\n",
      "====================\n",
      "input:\trecetion\n",
      "target:\trecession\n",
      "pred:\tmnnnnnnn\n",
      "====================\n",
      "input:\tscadual\n",
      "target:\tschedule\n",
      "pred:\tmnnnnnn\n",
      "0.018609402626783796\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161c8304-9cce-4bb2-a758-3090b8b9a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num pair: 50\n",
      "====================\n",
      "input:\tapreciate\n",
      "target:\tappreciate\n",
      "pred:\tfirpreciate\n",
      "====================\n",
      "input:\tappeciate\n",
      "target:\tappreciate\n",
      "pred:\tfippeciate\n",
      "====================\n",
      "input:\tapprciate\n",
      "target:\tappreciate\n",
      "pred:\tfirpricate\n",
      "====================\n",
      "input:\tapprecate\n",
      "target:\tappreciate\n",
      "pred:\tfirpract\n",
      "====================\n",
      "input:\tapprecite\n",
      "target:\tappreciate\n",
      "pred:\tfirprect\n",
      "====================\n",
      "input:\tluve\n",
      "target:\tlove\n",
      "pred:\tluve\n",
      "====================\n",
      "input:\tculd\n",
      "target:\tcold\n",
      "pred:\tjuld\n",
      "====================\n",
      "input:\theart\n",
      "target:\theart\n",
      "pred:\tloud\n",
      "====================\n",
      "input:\tteleviseon\n",
      "target:\ttelevision\n",
      "pred:\tkelvection\n",
      "====================\n",
      "input:\tthone\n",
      "target:\tphone\n",
      "pred:\thunone\n",
      "====================\n",
      "input:\tphace\n",
      "target:\tphase\n",
      "pred:\tpuse\n",
      "====================\n",
      "input:\tpoam\n",
      "target:\tpoem\n",
      "pred:\tpoem\n",
      "====================\n",
      "input:\ttomorraw\n",
      "target:\ttomorrow\n",
      "pred:\tmomorry\n",
      "====================\n",
      "input:\tpresishan\n",
      "target:\tprecision\n",
      "pred:\tpursestan\n",
      "====================\n",
      "input:\tpresishion\n",
      "target:\tprecision\n",
      "pred:\tpression\n",
      "====================\n",
      "input:\tpresisian\n",
      "target:\tprecision\n",
      "pred:\tpursision\n",
      "====================\n",
      "input:\tpresistion\n",
      "target:\tprecision\n",
      "pred:\tpressition\n",
      "====================\n",
      "input:\tperver\n",
      "target:\tprefer\n",
      "pred:\tpurver\n",
      "====================\n",
      "input:\tpredgudice\n",
      "target:\tprejudice\n",
      "pred:\tjudge\n",
      "====================\n",
      "input:\tpredgudis\n",
      "target:\tprejudice\n",
      "pred:\tjudges\n",
      "====================\n",
      "input:\trecievor\n",
      "target:\treceiver\n",
      "pred:\treseriover\n",
      "====================\n",
      "input:\treciover\n",
      "target:\treceiver\n",
      "pred:\trescover\n",
      "====================\n",
      "input:\trelieve\n",
      "target:\trelief\n",
      "pred:\trelieve\n",
      "====================\n",
      "input:\ttogather\n",
      "target:\ttogether\n",
      "pred:\tjother\n",
      "====================\n",
      "input:\tremuttance\n",
      "target:\tremittance\n",
      "pred:\tremuntance\n",
      "====================\n",
      "input:\tdeposite\n",
      "target:\tdeposit\n",
      "pred:\tjespocit\n",
      "====================\n",
      "input:\tdeposittt\n",
      "target:\tdeposit\n",
      "pred:\tdispotent\n",
      "====================\n",
      "input:\tpeper\n",
      "target:\tpepper\n",
      "pred:\tsupper\n",
      "====================\n",
      "input:\tpepperrr\n",
      "target:\tpepper\n",
      "pred:\tsupper\n",
      "====================\n",
      "input:\temploye\n",
      "target:\temployee\n",
      "pred:\tmelploy\n",
      "====================\n",
      "input:\temployezz\n",
      "target:\temployee\n",
      "pred:\tmillesing\n",
      "====================\n",
      "input:\tbeest\n",
      "target:\tbest\n",
      "pred:\tmyster\n",
      "====================\n",
      "input:\tbestt\n",
      "target:\tbest\n",
      "pred:\tmust\n",
      "====================\n",
      "input:\taset\n",
      "target:\tbest\n",
      "pred:\tlost\n",
      "====================\n",
      "input:\tfeeture\n",
      "target:\tfeature\n",
      "pred:\tfurater\n",
      "====================\n",
      "input:\tfaeture\n",
      "target:\tfeature\n",
      "pred:\tfutery\n",
      "====================\n",
      "input:\tfeatture\n",
      "target:\tfeature\n",
      "pred:\tfunater\n",
      "====================\n",
      "input:\tgorges\n",
      "target:\tgorgeous\n",
      "pred:\tjorge\n",
      "====================\n",
      "input:\tgorgeus\n",
      "target:\tgorgeous\n",
      "pred:\tjargeous\n",
      "====================\n",
      "input:\tgourgace\n",
      "target:\tgorgeous\n",
      "pred:\tjargage\n",
      "====================\n",
      "input:\tgripe\n",
      "target:\tgrip\n",
      "pred:\tjip\n",
      "====================\n",
      "input:\thienous\n",
      "target:\theinous\n",
      "pred:\tithinuous\n",
      "====================\n",
      "input:\thurple\n",
      "target:\tpurple\n",
      "pred:\tjurple\n",
      "====================\n",
      "input:\toccassional\n",
      "target:\toccasional\n",
      "pred:\toccasional\n",
      "====================\n",
      "input:\ttirumph\n",
      "target:\ttriumph\n",
      "pred:\tjurmph\n",
      "====================\n",
      "input:\ttriam\n",
      "target:\ttriumph\n",
      "pred:\tgritam\n",
      "====================\n",
      "input:\tunforgatealbe\n",
      "target:\tunforgettable\n",
      "pred:\tunforgeable\n",
      "====================\n",
      "input:\tunforgattable\n",
      "target:\tunforgettable\n",
      "pred:\tunforgetable\n",
      "====================\n",
      "input:\tvesiable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "====================\n",
      "input:\tvisable\n",
      "target:\tvisible\n",
      "pred:\tvisible\n",
      "0.3370224396236412\n"
     ]
    }
   ],
   "source": [
    "test(encoder1, decoder1, new_test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d62af60-2295-4fe0-a939-cbd974d7783d",
   "metadata": {},
   "source": [
    "https://github.com/gaushh/Deep-Spelling <br>\n",
    "https://medium.com/analytics-vidhya/batching-strategies-for-lstm-input-6f18089b1735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8051015-d5e2-4a1e-983f-1012fe37338d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
